<!DOCTYPE html>
<html lang="en">
<head>
    <title>Learning Disentangled Speech Representations</title>
    <link href="https://fonts.googleapis.com/css?family=Crimson+Text:400,400i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="index.css">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>

    <div class='section'>
        <h1>Learning Disentangled Speech Representations</h1>
        <p>This work was accepted and presented as a poster at the <strong>New in ML</strong> workshop at <strong>NeurIPS 2023</strong>, the Thirty-Seventh Annual Conference on Neural Information Processing Systems.</p>
        <p>The audio samples below accompany the paper <i>Learning Disentangled Speech Representations</i>.</p>
        
        <h4>Contents:</h4>
        <ul class='toc'>
            <li><a href='#speaker_samples'>Speaker Samples</a></li>
            <li><a href='#synspeech'>SynSpeech Dataset</a></li>
            <li><a href='#rave_analysis'>RAVE Analysis</a></li>
            <li><a href='#chimpanzee_analysis'>Chimpanzee Analysis</a></li>
        </ul>
    </div>

    <hr>

    <!-- Speaker Samples Section -->
    <div id='speaker_samples' class='section'>
        <h2>Speaker Samples</h2>
        <p>Here we present audio samples for male and female speakers across different speaking styles.</p>

        <table>
            <tr>
                <th>Speaker</th>
                <th>Default</th>
                <th>Friendly</th>
                <th>Sad</th>
                <th>Whispering</th>
            </tr>
            
            <!-- Male Speaker Row -->
            <tr>
                <td>Male</td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_male_1040_default.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_male_1040_friendly.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_male_1040_sad.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_male_1040_whispering.wav' type='audio/mpeg'></audio></td>
            </tr>
            
            <!-- Female Speaker Row -->
            <tr>
                <td>Female</td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_female_7178_default.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_female_7178_friendly.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_female_7178_sad.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/SynSpeech25/sample_female_7178_whispering.wav' type='audio/mpeg'></audio></td>
            </tr>
        </table>
    </div>

    <hr>

    <!-- SynSpeech Dataset Description -->
    <div id='synspeech' class='section'>
        <h2>SynSpeech Dataset Versions</h2>
        <p>
            To enable standardized evaluation of disentangled speech representation learning, we created SynSpeech, a large-scale synthetic speech dataset comprising over 160,000 utterances generated using state-of-the-art neural text-to-speech models. SynSpeech includes ground truth annotations for key generative factors: speaker identity, spoken text, prosody (pitch and loudness variations), and emotional tone (neutral, happy, angry).
            By varying one factor at a time, SynSpeech enables models to isolate individual sources of variation effectively. The dataset is open-sourced to facilitate research and standardized evaluation in speech disentanglement.
        </p>
        <p>
            SynSpeech includes controlled variations in content, speaker identity, and speaking style. Using the GPT-4 Large Language Model, we generated 500 diverse sentences across discourse contexts, from casual dialogue to scientific explanation. The speaker set includes 249 speakers from the LibriSpeech100 dataset, balanced across gender. Each sentence is synthesized for all speaker profiles to create structured combinations of speaker identity and content.
        </p>
        <p>
            For additional diversity, we employed the OpenVoice toolkit to synthesize each sentence across four distinct styles: default, happy, sad, and whispering, resulting in 498,000 samples at a 16kHz rate. SynSpeech thus enables detailed evaluation of disentangling complex attributes in synthetic speech data.
        </p>
        <h3>Dataset Versions</h3>
        <table>
            <tr>
                <th>Version</th>
                <th>Speakers</th>
                <th>Contents</th>
                <th>Styles</th>
                <th>Total</th>
            </tr>
            <tr>
                <td>Small</td>
                <td>50</td>
                <td>500</td>
                <td>1</td>
                <td>25,000</td>
            </tr>
            <tr>
                <td>Medium</td>
                <td>25</td>
                <td>500</td>
                <td>4</td>
                <td>50,000</td>
            </tr>
            <tr>
                <td>Large</td>
                <td>249</td>
                <td>110</td>
                <td>4</td>
                <td>109,560</td>
            </tr>
        </table>

     <!-- RAVE Analysis -->
    <div id='rave_analysis' class='section'>
        <h2>Speech Representation Learning with RAVE on Small dataset</h2>
        <p>This section demonstrates speech representation learning performed using RAVE, showcasing original, reconstructed, and generated samples.</p>

        <table>
            <tr>
                <th>Original</th>
                <th>Reconstructed</th>
                <th>Generated</th>
            </tr>
            
            <!-- Row 1 -->
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample0.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample0.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample0.wav' type='audio/mpeg'></audio></td>
            </tr>
            <!-- Repeat for the next 15 rows -->
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample1.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample1.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample1.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample2.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample2.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample2.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample3.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample3.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample3.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample4.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample4.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample4.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample5.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample5.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample5.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample6.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample6.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample6.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample7.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample7.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample7.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample8.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample8.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample8.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample9.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample9.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample9.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample10.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample10.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample10.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample11.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample11.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample11.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample12.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample12.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample12.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample13.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample13.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample13.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample14.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample14.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample14.wav' type='audio/mpeg'></audio></td>
            </tr>
            <tr>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/original_batch0_sample15.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/reconstructed_batch0_sample15.wav' type='audio/mpeg'></audio></td>
                <td><audio preload='metadata' controls><source src='GeneratedSamples/Samples/generated_batch0_sample15.wav' type='audio/mpeg'></audio></td>
            </tr>
            <!-- Additional rows can be added for other samples if available -->
        </table>
    </div>

    <hr>

    <!-- Chimpanzee Analysis -->
    <div id='chimpanzee_analysis' class='section'>
        <h2>Chimpanzee Analysis</h2>
        <p>Examining disentanglement of factors in chimpanzee vocalizations using similar techniques as with human speech.</p>

        <h3>Originals vs Reconstructions</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/wavenet_unconditional/blizzard/sample-0.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/wavenet_unconditional/blizzard/sample-1.mp3' type='audio/mpeg'></audio></div>
        </div>
        
        <h3>Generated Samples</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/wavenet_primed/blizzard/sample-0.mp3' type='audio/mpeg'></audio></div>
        </div>
    </div>

    <hr>

    <!-- Affiliations -->
    <div class='section'>
        <h2>Author Affiliations</h2>
        <p>Yusuf Brima<sup>1,2,*</sup>, Ulf Krumnack<sup>1</sup>, Simone Pika<sup>2</sup>, Gunther Heidemann<sup>1</sup></p>
        <p><sup>1</sup>Computer Vision, <sup>2</sup>Comparative BioCognition, *Corresponding author</p>
        <p>Institute of Cognitive Science, Universität Osnabrück, Germany</p>
        <p><a href="mailto:ybrima@uos.de">ybrima@uos.de</a>, <a href="mailto:krumnack@uos.de">krumnack@uos.de</a>, <a href="mailto:spika@uos.de">spika@uos.de</a>, <a href="mailto:gheidema@uos.de">gheidema@uos.de</a></p>
        <p><a href="https://arxiv.org/abs/2311.03389">Link to the paper</a></p>
    </div>

</body>
</html>
