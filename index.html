<!DOCTYPE html>
<html lang="en">
<head>
    <title>Learning Disentangled Speech Representations</title>
    <link href="https://fonts.googleapis.com/css?family=Crimson+Text:400,400i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="index.css">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>

    <div class='section'>
        <h1>Learning Disentangled Speech Representations</h1>
        <p>Audio samples accompanying the paper <i>Learning Disentangled Speech Representations</i>.</p>
        <h4>Contents:</h4>
        <ul class='toc'>
            <li><a href='#synspeech'>SynSpeech Dataset Versions</a></li>
            <li><a href='#rave_analysis'>RAVE Analysis</a></li>
            <li><a href='#chimpanzee_analysis'>Chimpanzee Analysis</a></li>
        </ul>
    </div>

    <hr>

    <!-- SynSpeech Dataset Versions -->
    <div id='synspeech' class='section'>
        <h2>SynSpeech Dataset Versions</h2>
        <p>Introducing the SynSpeech dataset in three distinct versions to support research in disentangled speech representation learning.</p>
        
        <!-- Version 1 -->
        <h3>Version 1 - Originals vs Reconstructions</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_unconditional/sample-0.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_biased/sample-0.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional samples as needed -->
        </div>
        
        <h3>Version 1 - Generated Samples</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_primed/sample-0.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional generated samples -->
        </div>

        <!-- Repeat for Versions 2 and 3 with similar structure -->
        
        <h3>Version 2 - Originals vs Reconstructions</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/voxceleb2_unconditional/sample-0.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/voxceleb2_unconditional/sample-1.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional samples for Version 2 -->
        </div>
        
        <h3>Version 2 - Generated Samples</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/voxceleb2_unconditional/sample-2.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional generated samples for Version 2 -->
        </div>
        
        <h3>Version 3 - Originals vs Reconstructions</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/music/sample-0.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/music/sample-1.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional samples for Version 3 -->
        </div>
        
        <h3>Version 3 - Generated Samples</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/music_primed/sample-0.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional generated samples for Version 3 -->
        </div>
    </div>

    <hr>

    <!-- RAVE Analysis -->
    <div id='rave_analysis' class='section'>
        <h2>Speech Representation Learning with RAVE</h2>
        <p>This section demonstrates speech representation learning performed using RAVE.</p>

        <h3>Originals vs Reconstructions</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-0/real.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-0/fake-0.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional RAVE originals vs reconstructions samples -->
        </div>
        
        <h3>Generated Samples</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_primed/sample/sample-0.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional RAVE generated samples -->
        </div>
    </div>

    <hr>

    <!-- Chimpanzee Analysis -->
    <div id='chimpanzee_analysis' class='section'>
        <h2>Chimpanzee Analysis</h2>
        <p>Examining disentanglement of factors in chimpanzee vocalizations using similar techniques as with human speech.</p>

        <h3>Originals vs Reconstructions</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/wavenet_unconditional/blizzard/sample-0.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/wavenet_unconditional/blizzard/sample-1.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional chimpanzee originals vs reconstructions samples -->
        </div>
        
        <h3>Generated Samples</h3>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/wavenet_primed/blizzard/sample-0.mp3' type='audio/mpeg'></audio></div>
            <!-- Additional chimpanzee generated samples -->
        </div>
    </div>

    <hr>

    <!-- Affiliations -->
    <div class='section'>
        <h2>Author Affiliations</h2>
        <p>Yusuf Brima<sup>1,2,*</sup>, Ulf Krumnack<sup>1</sup>, Simone Pika<sup>2</sup>, Gunther Heidemann<sup>1</sup></p>
        <p><sup>1</sup>Computer Vision, <sup>2</sup>Comparative BioCognition, *Corresponding author</p>
        <p>Institute of Cognitive Science, Universität Osnabrück, Germany</p>
        <p><a href="mailto:ybrima@uos.de">ybrima@uos.de</a>, <a href="mailto:krumnack@uos.de">krumnack@uos.de</a>, <a href="mailto:spika@uos.de">spika@uos.de</a>, <a href="mailto:gheidema@uos.de">gheidema@uos.de</a></p>
        <p><a href="https://arxiv.org/abs/2311.03389">Link to the paper</a></p>
    </div>

</body>
</html>